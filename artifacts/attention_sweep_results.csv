K_N,Q_N,avg_ms,batch_size,error,head_dim,kernel,min_ms,num_heads,std_ms,tier
512,512,9.2754,8,,64,scaled_dot_prod_attention,3.5937,12,1.8403,seq512-hd64-12h-8b
1024,1024,19.6914,8,,64,scaled_dot_prod_attention,13.2742,12,8.0418,seq1024-hd64-12h-8b
2048,2048,58.5596,8,,64,scaled_dot_prod_attention,56.8635,12,4.4808,seq2048-hd64-12h-8b
4096,4096,0,8,"CUDA out of memory. Tried to allocate 3.00 GiB. GPU 0 has a total capacity of 11.63 GiB of which 2.10 GiB is free. Process 2186671 has 178.00 MiB memory in use. Process 2191990 has 9.34 GiB memory in use. Of the allocated memory 9.17 GiB is allocated by PyTorch, and 41.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",64,scaled_dot_prod_attention,0,12,0,seq4096-hd64-12h-8b
8192,8192,0,8,"CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacity of 11.63 GiB of which 8.10 GiB is free. Process 2186671 has 178.00 MiB memory in use. Process 2191990 has 3.34 GiB memory in use. Of the allocated memory 296.12 MiB is allocated by PyTorch, and 2.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",64,scaled_dot_prod_attention,0,12,0,seq8192-hd64-12h-8b
16384,16384,0,8,"CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 11.63 GiB of which 8.10 GiB is free. Process 2186671 has 178.00 MiB memory in use. Process 2191990 has 3.34 GiB memory in use. Of the allocated memory 584.12 MiB is allocated by PyTorch, and 2.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",64,scaled_dot_prod_attention,0,12,0,seq16384-hd64-12h-8b
512,512,22.0808,32,,128,scaled_dot_prod_attention,18.0933,16,11.0212,seq512-hd128-16h-32b
1024,1024,97.6798,32,,128,scaled_dot_prod_attention,75.0704,16,32.8425,seq1024-hd128-16h-32b
2048,2048,0,32,"CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 11.63 GiB of which 3.19 GiB is free. Process 2186671 has 178.00 MiB memory in use. Process 2191990 has 7.15 GiB memory in use. Process 2193273 has 1.09 GiB memory in use. Of the allocated memory 4.76 GiB is allocated by PyTorch, and 2.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",128,scaled_dot_prod_attention,0,16,0,seq2048-hd128-16h-32b
4096,4096,0,32,"CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 11.63 GiB of which 7.19 GiB is free. Process 2186671 has 178.00 MiB memory in use. Process 2191990 has 3.15 GiB memory in use. Process 2193273 has 1.09 GiB memory in use. Of the allocated memory 1.51 GiB is allocated by PyTorch, and 1.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",128,scaled_dot_prod_attention,0,16,0,seq4096-hd128-16h-32b
8192,8192,0,32,"CUDA out of memory. Tried to allocate 64.00 GiB. GPU 0 has a total capacity of 11.63 GiB of which 7.19 GiB is free. Process 2186671 has 178.00 MiB memory in use. Process 2191990 has 3.15 GiB memory in use. Process 2193273 has 1.09 GiB memory in use. Of the allocated memory 3.01 GiB is allocated by PyTorch, and 11.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",128,scaled_dot_prod_attention,0,16,0,seq8192-hd128-16h-32b
16384,16384,0,32,"CUDA out of memory. Tried to allocate 256.00 GiB. GPU 0 has a total capacity of 11.63 GiB of which 3.19 GiB is free. Process 2186671 has 178.00 MiB memory in use. Process 2191990 has 7.15 GiB memory in use. Process 2193273 has 1.09 GiB memory in use. Of the allocated memory 6.01 GiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",128,scaled_dot_prod_attention,0,16,0,seq16384-hd128-16h-32b
512,512,7.1042,8,,64,vectorized_torch,3.7354,12,1.0818,seq512-hd64-12h-8b
1024,1024,21.0407,8,,64,vectorized_torch,11.9808,12,6.0745,seq1024-hd64-12h-8b
2048,2048,65.1321,8,,64,vectorized_torch,47.0229,12,23.492,seq2048-hd64-12h-8b
4096,4096,0,8,"CUDA out of memory. Tried to allocate 3.00 GiB. GPU 0 has a total capacity of 11.63 GiB of which 2.19 GiB is free. Process 2186671 has 178.00 MiB memory in use. Process 2191990 has 8.15 GiB memory in use. Process 2193273 has 1.09 GiB memory in use. Of the allocated memory 6.16 GiB is allocated by PyTorch, and 1.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",64,vectorized_torch,0,12,0,seq4096-hd64-12h-8b
8192,8192,0,8,"CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacity of 11.63 GiB of which 8.19 GiB is free. Process 2186671 has 178.00 MiB memory in use. Process 2191990 has 2.15 GiB memory in use. Process 2193273 has 1.09 GiB memory in use. Of the allocated memory 296.12 MiB is allocated by PyTorch, and 1.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",64,vectorized_torch,0,12,0,seq8192-hd64-12h-8b
16384,16384,0,8,"CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 11.63 GiB of which 8.19 GiB is free. Process 2186671 has 178.00 MiB memory in use. Process 2191990 has 2.15 GiB memory in use. Process 2193273 has 1.09 GiB memory in use. Of the allocated memory 584.12 MiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",64,vectorized_torch,0,12,0,seq16384-hd64-12h-8b
512,512,29.5341,32,,128,vectorized_torch,16.6072,16,9.1936,seq512-hd128-16h-32b
1024,1024,108.2373,32,,128,vectorized_torch,67.0144,16,34.1782,seq1024-hd128-16h-32b
2048,2048,0,32,"CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 11.63 GiB of which 196.56 MiB is free. Process 2186671 has 178.00 MiB memory in use. Process 2191990 has 10.15 GiB memory in use. Process 2193273 has 1.09 GiB memory in use. Of the allocated memory 8.76 GiB is allocated by PyTorch, and 1.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",128,vectorized_torch,0,16,0,seq2048-hd128-16h-32b
4096,4096,0,32,"CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 11.63 GiB of which 8.19 GiB is free. Process 2186671 has 178.00 MiB memory in use. Process 2191990 has 2.15 GiB memory in use. Process 2193273 has 1.09 GiB memory in use. Of the allocated memory 1.51 GiB is allocated by PyTorch, and 523.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",128,vectorized_torch,0,16,0,seq4096-hd128-16h-32b
8192,8192,0,32,"CUDA out of memory. Tried to allocate 64.00 GiB. GPU 0 has a total capacity of 11.63 GiB of which 7.19 GiB is free. Process 2186671 has 178.00 MiB memory in use. Process 2191990 has 3.15 GiB memory in use. Process 2193273 has 1.09 GiB memory in use. Of the allocated memory 3.01 GiB is allocated by PyTorch, and 11.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",128,vectorized_torch,0,16,0,seq8192-hd128-16h-32b
16384,16384,0,32,"CUDA out of memory. Tried to allocate 256.00 GiB. GPU 0 has a total capacity of 11.63 GiB of which 4.19 GiB is free. Process 2186671 has 178.00 MiB memory in use. Process 2191990 has 6.15 GiB memory in use. Process 2193273 has 1.09 GiB memory in use. Of the allocated memory 6.01 GiB is allocated by PyTorch, and 11.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",128,vectorized_torch,0,16,0,seq16384-hd128-16h-32b
512,512,0.8049,8,,64,vectorized_torch_compiled,0.783,12,0.1217,seq512-hd64-12h-8b
1024,1024,7.6356,8,,64,vectorized_torch_compiled,4.2424,12,1.0436,seq1024-hd64-12h-8b
2048,2048,21.4625,8,,64,vectorized_torch_compiled,12.0098,12,5.6356,seq2048-hd64-12h-8b
4096,4096,67.3988,8,,64,vectorized_torch_compiled,45.5284,12,21.7236,seq4096-hd64-12h-8b
8192,8192,0,8,"CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacity of 11.63 GiB of which 8.19 GiB is free. Process 2186671 has 178.00 MiB memory in use. Process 2191990 has 2.15 GiB memory in use. Process 2193273 has 1.09 GiB memory in use. Of the allocated memory 296.12 MiB is allocated by PyTorch, and 1.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",64,vectorized_torch_compiled,0,12,0,seq8192-hd64-12h-8b
16384,16384,0,8,"CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 11.63 GiB of which 8.19 GiB is free. Process 2186671 has 178.00 MiB memory in use. Process 2191990 has 2.15 GiB memory in use. Process 2193273 has 1.09 GiB memory in use. Of the allocated memory 584.12 MiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",64,vectorized_torch_compiled,0,12,0,seq16384-hd64-12h-8b
512,512,7.7848,32,,128,vectorized_torch_compiled,7.6793,16,0.1612,seq512-hd128-16h-32b
1024,1024,31.8293,32,,128,vectorized_torch_compiled,30.0544,16,3.5766,seq1024-hd128-16h-32b
2048,2048,182.952,32,,128,vectorized_torch_compiled,137.212,16,62.3671,seq2048-hd128-16h-32b
4096,4096,0,32,"CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 11.63 GiB of which 8.02 GiB is free. Process 2186671 has 178.00 MiB memory in use. Process 2191990 has 2.15 GiB memory in use. Process 2197712 has 1.26 GiB memory in use. Of the allocated memory 1.51 GiB is allocated by PyTorch, and 523.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",128,vectorized_torch_compiled,0,16,0,seq4096-hd128-16h-32b
8192,8192,0,32,"CUDA out of memory. Tried to allocate 64.00 GiB. GPU 0 has a total capacity of 11.63 GiB of which 7.02 GiB is free. Process 2186671 has 178.00 MiB memory in use. Process 2191990 has 3.15 GiB memory in use. Process 2197712 has 1.26 GiB memory in use. Of the allocated memory 3.01 GiB is allocated by PyTorch, and 11.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",128,vectorized_torch_compiled,0,16,0,seq8192-hd128-16h-32b
16384,16384,0,32,"CUDA out of memory. Tried to allocate 256.00 GiB. GPU 0 has a total capacity of 11.63 GiB of which 4.02 GiB is free. Process 2186671 has 178.00 MiB memory in use. Process 2191990 has 6.15 GiB memory in use. Process 2197712 has 1.26 GiB memory in use. Of the allocated memory 6.01 GiB is allocated by PyTorch, and 11.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",128,vectorized_torch_compiled,0,16,0,seq16384-hd128-16h-32b
512,512,1.8274,8,,64,flash_attention_triton,0.7605,12,7.3627,seq512-hd64-12h-8b
1024,1024,6.4925,8,,64,flash_attention_triton,3.3998,12,1.1074,seq1024-hd64-12h-8b
2048,2048,11.1897,8,,64,flash_attention_triton,11.0788,12,0.3333,seq2048-hd64-12h-8b
4096,4096,37.4668,8,,64,flash_attention_triton,37.4521,12,0.0075,seq4096-hd64-12h-8b
8192,8192,149.8888,8,,64,flash_attention_triton,149.86,12,0.0147,seq8192-hd64-12h-8b
16384,16384,599.0627,8,,64,flash_attention_triton,599.0042,12,0.0534,seq16384-hd64-12h-8b
512,512,8.1663,32,,128,flash_attention_triton,8.0727,16,0.0361,seq512-hd128-16h-32b
1024,1024,31.4655,32,,128,flash_attention_triton,31.4182,16,0.1029,seq1024-hd128-16h-32b
2048,2048,123.5675,32,,128,flash_attention_triton,123.4891,16,0.0278,seq2048-hd128-16h-32b
4096,4096,493.0789,32,,128,flash_attention_triton,492.9344,16,0.0799,seq4096-hd128-16h-32b
8192,8192,2568.9467,32,,128,flash_attention_triton,2101.5956,16,764.7284,seq8192-hd128-16h-32b
16384,16384,7850.0253,32,,128,flash_attention_triton,7848.7817,16,0.4664,seq16384-hd128-16h-32b
