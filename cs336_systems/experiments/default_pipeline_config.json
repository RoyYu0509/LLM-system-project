{
  "dataset_mode": "tinystories",

  "tinystories_train_url": "https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStoriesV2-GPT4-train.txt",
  "tinystories_valid_url": "https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStoriesV2-GPT4-valid.txt",

  "raw_train_text": "cs336-basics/data/ts_train.txt",
  "raw_valid_text": "cs336-basics/data/ts_valid.txt",

  "vocab_path": "cs336-basics/cs336_basics/bpe_tokenizer/vocab.pkl",
  "merges_path": "cs336-basics/cs336_basics/bpe_tokenizer/merges.pkl",

  "tokenized_train": "cs336-basics/data/tokenized/ts_train.npy",
  "tokenized_valid": "cs336-basics/data/tokenized/ts_valid.npy",

  "model": {
    "vocab_size": 10000,
    "context_length": 256,
    "num_layers": 4,
    "d_model": 512,
    "num_heads": 16,
    "d_ff": 1344,
    "rope_theta": 10000.0
  },

  "training": {
    "tr_batch_size": 8,
    "val_batch_size": 8,
    "val_bat_num": 50,
    "epochs": 10,
    "lr": 0.0006,
    "weight_decay": 0.01,
    "beta1": 0.9,
    "beta2": 0.999,
    "adam_eps": 1e-8,
    "grad_clip": 1.0,
    "max_iters": 5000,
    "warmup_iters": 1500,
    "dtype": "float32",
    "compile": true,
    "seed": 0
  },

  "checkpointing": {
    "checkpoint_dir": "checkpoints",
    "log_interval": 50,
    "eval_interval": 100,
    "checkpointing_interval": 400
  },

  "wandb": {
    "project": "Train_Transformer_LM",
    "run_name": null
  },

  "attention_kernel": "scaled_dot_prod_attention",
  "ddp_wrapper": "none",

  "bucket_size_mb": 1
}
